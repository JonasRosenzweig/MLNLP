{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make a script that can make sure we have same amount of negative and positive rows.\n",
    "import os\n",
    "import pandas as pd\n",
    "#\n",
    "# DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "# DATASET_ENCODING = \"ISO-8859-1\"\n",
    "#\n",
    "# filename = os.listdir(\"C:\\\\Users\\\\HE400\\\\PycharmProjects\\\\MLNLP2\\\\Tutorials_and_References\\\\notebookGold\\\\input\")[0]\n",
    "# filename2 = os.listdir(\"C:\\\\Users\\\\HE400\\\\PycharmProjects\\\\MLNLP2\\\\Tutorials_and_References\\\\notebookGold\\\\input\")[1]\n",
    "#\n",
    "# dataset_path = os.path.join(\"..\",\n",
    "#                             \"C:\\\\Users\\\\HE400\\\\PycharmProjects\\\\MLNLP2\\\\Tutorials_and_References\\\\notebookGold\\\\input\",\n",
    "#                             filename)\n",
    "# dataset_path2 = os.path.join(\"..\",\n",
    "#                             \"C:\\\\Users\\\\HE400\\\\PycharmProjects\\\\MLNLP2\\\\Tutorials_and_References\\\\notebookGold\\\\input\",\n",
    "#                             filename2)\n",
    "#\n",
    "# df = pd.read_csv(dataset_path, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "# df2 = pd.read_csv(dataset_path2, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "#\n",
    "# dff = pd.concat([df, df2])\n",
    "# gg = pd.DataFrame(dff)\n",
    "# gg.to_csv('test.csv', index = False, header=False)\n",
    "\n",
    "\n",
    "datasetPath = 'C:\\\\Users\\\\HE400\\\\PycharmProjects\\\\MLNLP2\\\\Tutorials_and_References\\\\notebookGold\\\\input\\\\test.csv'\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "def createEvenDistData(datasetPath, length):\n",
    "    df = pd.read_csv(datasetPath, encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "    positive = df.loc[df['target'] == 4] #loc selects the rows where the target(column) value equals to the condition:\n",
    "    negative = df.loc[df['target'] == 0]\n",
    "\n",
    "\n",
    "    print('POS:', positive)\n",
    "    print('NEG:', negative)\n",
    "\n",
    "    print(len(positive))\n",
    "    print(len(negative))\n",
    "\n",
    "    if len(positive) & len(negative) != length:\n",
    "        positive = positive[:length]\n",
    "        negative = negative[:length]\n",
    "        print(\"debug1\", positive)\n",
    "        print(len(positive))\n",
    "\n",
    "        print(\"debug2\", negative)\n",
    "\n",
    "        dataConcat = pd.concat([positive,negative])\n",
    "        mergedDataset = pd.DataFrame(dataConcat)\n",
    "        #mergedDataset.to_csv('ASFGSAGASDSAGASDAS.csv', index=False, header=False)\n",
    "        dataConcat.to_csv('AMAZING.csv', index=False, header=False)\n",
    "        print(\"TASK SUCCESSFUL!\")\n",
    "\n",
    "    elif len(positive) & len(negative) == length:\n",
    "        dataConcat = pd.concat([positive,negative])\n",
    "        dataConcat.to_csv('noChange.csv', index=False)\n",
    "        print('No Change made!')\n",
    "\n",
    "    else:\n",
    "        print('Failed...!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS:       target         ids                          date      flag  \\\n",
      "0          4  1685554916  Sun May 03 00:55:35 PDT 2009  NO_QUERY   \n",
      "1          4  1685555003  Sun May 03 00:55:36 PDT 2009  NO_QUERY   \n",
      "2          4  1685555064  Sun May 03 00:55:37 PDT 2009  NO_QUERY   \n",
      "3          4  1685555173  Sun May 03 00:55:39 PDT 2009  NO_QUERY   \n",
      "4          4  1685555303  Sun May 03 00:55:41 PDT 2009  NO_QUERY   \n",
      "...      ...         ...                           ...       ...   \n",
      "9995       4  1687900122  Sun May 03 09:51:58 PDT 2009  NO_QUERY   \n",
      "9996       4  1687900139  Sun May 03 09:51:58 PDT 2009  NO_QUERY   \n",
      "9997       4  1687900201  Sun May 03 09:51:59 PDT 2009  NO_QUERY   \n",
      "9998       4  1687900215  Sun May 03 09:51:59 PDT 2009  NO_QUERY   \n",
      "9999       4  1687900229  Sun May 03 09:51:59 PDT 2009  NO_QUERY   \n",
      "\n",
      "                 user                                               text  \n",
      "0          Deva09IAME  Depending on what time zone you are, good morn...  \n",
      "1              Jag999              @irishpixie36 hey good luck !!!!!!  x  \n",
      "2     PierreBeachbody  It is late but I HAD to have some #shakeology ...  \n",
      "3               Quimo  @Gaelicwolf Who ME *innocent smile* but @Twist...  \n",
      "4         suziemclean      @miatyler: I love laughing at drunk ppl too.   \n",
      "...               ...                                                ...  \n",
      "9995  christineclarke  I'm going on vacation in just 7 weeks. Going t...  \n",
      "9996           drkiki  @AaronWarner Thank you for the link!!! This is...  \n",
      "9997         themunny                                   @movieho hahaha   \n",
      "9998         juliaalx  Am outside on the balcony, chilling, reading a...  \n",
      "9999  healthyirishman                               @tipp_princess done   \n",
      "\n",
      "[10000 rows x 6 columns]\n",
      "NEG:        target         ids                          date      flag  \\\n",
      "10000       0  2296459500  Tue Jun 23 09:12:36 PDT 2009  NO_QUERY   \n",
      "10001       0  2296459611  Tue Jun 23 09:12:35 PDT 2009  NO_QUERY   \n",
      "10002       0  2296459890  Tue Jun 23 09:12:37 PDT 2009  NO_QUERY   \n",
      "10003       0  2296460589  Tue Jun 23 09:12:40 PDT 2009  NO_QUERY   \n",
      "10004       0  2296461120  Tue Jun 23 09:12:43 PDT 2009  NO_QUERY   \n",
      "...       ...         ...                           ...       ...   \n",
      "19995       0  2301836078  Tue Jun 23 15:58:45 PDT 2009  NO_QUERY   \n",
      "19996       0  2301836497  Tue Jun 23 15:58:47 PDT 2009  NO_QUERY   \n",
      "19997       0  2301836808  Tue Jun 23 15:58:49 PDT 2009  NO_QUERY   \n",
      "19998       0  2301837406  Tue Jun 23 15:58:52 PDT 2009  NO_QUERY   \n",
      "19999       0  2301837469  Tue Jun 23 15:58:52 PDT 2009  NO_QUERY   \n",
      "\n",
      "               user                                               text  \n",
      "10000  samecraft424  @AngelIbarra Im sure you're bummed bout leavin...  \n",
      "10001      bluzgrrl  RIP - great blues musician Nick Holt  http://b...  \n",
      "10002   InUrDreams5  Bama isn't doing well, they are going to leave...  \n",
      "10003     debbiferr  i miss peoplee  come backkk. chrissy. bio is a...  \n",
      "10004      waireyes  @Bumatay Yes I did, it was so graphic! Such a ...  \n",
      "...             ...                                                ...  \n",
      "19995    ohla_ambie               @ibesnorlax you aren't following me   \n",
      "19996       leftest                ..that want more than a bootishcall  \n",
      "19997     TomCallan                 GRUMPY TOM!       Such a long day!  \n",
      "19998       skweeds   @tclick    we will make you feel better #tweetup  \n",
      "19999         jenw2  @breelin I need to make it silly lol. I miss you   \n",
      "\n",
      "[10000 rows x 6 columns]\n",
      "10000\n",
      "10000\n",
      "No Change made!\n"
     ]
    }
   ],
   "source": [
    "createEvenDistData(datasetPath, 10000)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}